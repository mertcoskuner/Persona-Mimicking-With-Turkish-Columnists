# LLMs-Talking-Each-Other

Welcome to the **LLMs-Talking-Each-Other** project, developed as part of the ENS492 graduation project. This repository explores the  dynamics of communication between Large Language Models (LLMs) and demonstrates interactions both between LLMs and with users. 
## üìå Project Objectives

- Enable **LLM-to-LLM Communication**: Simulate dynamic and meaningful dialogues between multiple LLMs.
- Facilitate **User-to-LLM Interaction**: Allow users to interact with LLMs through text-based inputs.
- Investigate LLM dynamics in various scenarios, including collaborative and competitive interactions.
- Explore real-world applications of LLM dialogues in fields like education, entertainment, and AI research.

## üöÄ Features

- **LLM-to-LLM Dialogues**: Simulate rich and structured conversations between multiple LLM instances.
- **Persona-Based Communication**: Assign unique personas to LLMs for diverse and contextually tailored interactions.
- **Customizable Prompts**: Set initial prompts for LLMs to guide and shape their dialogues.
- **Interactive Backend**: Built with Flask or Django for scalable and efficient API services.

## üõ†Ô∏è Technologies Used

- **Large Language Models**: Powered by cutting-edge LLMs (e.g., Meta-Llama, TURKCELL-LLM, YTU-Cosmos, Gemma-2).
- **Backend**: Flask/Django for API and model serving.
- **Frontend**: Streamlit UI for enhanced user engagement.

## üí° Use Cases

- AI-powered social platforms with engaging dialogues.
- Virtual assistants capable of dynamic, multi-agent communication.
- Simulation tools for dialogue research and analysis.
- Educational tools for AI-driven learning experiences.



